# Logistic Regression
---
> [!info]+ File Details
> Includes information about this (genus:: Note) from [Year::2]. Contains details on when this was created, what module the note belongs to.
> > *Date :*  03-10-2024
> > *Module :* [[Machine Learning]]
> > *Teacher*: 
> > *Resources :*

---
> [!abstract]+ Contents
> List of headings within this topic
> > [[#Speed run]]
> [[#Logistic Regression]]
> [[#Loss Function]]
> [[#Example of Log-less]]
> [[#Multi Class Example]]

--- 
> [!danger]+ *Speed run*
> Break down of topic 
> > $a)$ -  
> $b)$ - 
> $c)$ - 

---

![[Pasted image 20241003155557.png]]
#TODO 

>[!info] ### Sigmoid Function
>The sigmoid functions goes between the values of 1 and 0. Hence it is perfect for probability and binary classificiation 
>Sigmoid is defined as the following : $$\frac{1}{ðŸ+e^{-x}}$$
>![[Sigmoid Function.png]]


## Loss Function

>[!info] ### Log-loss 
>Log-Loss is a standard classification evaluation metric. 
>$ð½(ðœƒ) =âˆ’[\log(â„Ž_ðœƒ(ð‘¥)) + (1 -y)\log(1 -â„Ž_ðœƒ(x))]$
>
![[Log-loss Function.png]]


### Example of Log-less

![[Example of Log-less.png



## Multi Class Example

![[Multi Class Example.png]]